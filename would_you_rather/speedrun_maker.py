import os
import random
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from moviepy.video.fx import LumContrast

# === MoviePy 2.x ä¸“ç”¨å¯¼å…¥æ–¹å¼ ===
from moviepy import (
    VideoFileClip,
    ImageClip,
    ColorClip,
    TextClip,
    CompositeVideoClip,
    clips_array,
    AudioFileClip,
    CompositeAudioClip,
    concatenate_audioclips
)
import moviepy.video.fx as vfx

# ================= é…ç½®åŒºåŸŸ =================
# å±å¹•å°ºå¯¸
W, H = 1080, 1920

# é¢œè‰²é…ç½® (çº¢è“å¯¹å†³)
COLOR_TOP = (200, 0, 0)  # æ·±çº¢
COLOR_BOTTOM = (0, 0, 200)  # æ·±è“
FONT_PATH = "Impact.ttf"  # è¯·ç¡®ä¿ç›®å½•ä¸‹æœ‰è¿™ä¸ªå­—ä½“æ–‡ä»¶

# éŸ³æ•ˆè·¯å¾„
SFX_TICK = "assets/sfx/tick.mp3"
SFX_BOOM = "assets/sfx/boom.mp3"


# ================= å·¥å…·å‡½æ•° =================

def create_text_img_pil(text, size, color='white', stroke_color='black'):
    """
    ä½¿ç”¨ PIL ç”Ÿæˆå¸¦æè¾¹çš„æ–‡å­—å›¾ç‰‡ (æ¯” MoviePy TextClip æ›´ç¨³å®š)
    """
    # åˆ›å»ºé€æ˜èƒŒæ™¯
    img = Image.new("RGBA", size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)

    try:
        # å°è¯•åŠ è½½å­—ä½“ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨é»˜è®¤
        font = ImageFont.truetype(FONT_PATH, 100)
    except OSError:
        print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ°å­—ä½“ {FONT_PATH}ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“")
        font = ImageFont.load_default()

    # è®¡ç®—æ–‡å­—å±…ä¸­
    bbox = draw.textbbox((0, 0), text, font=font)
    text_w = bbox[2] - bbox[0]
    text_h = bbox[3] - bbox[1]
    x = (size[0] - text_w) / 2
    y = (size[1] - text_h) / 2

    # å°†é¢œè‰²è½¬æ¢ä¸ºRGBå€¼
    if color == '#FFFF00':
        color = (255, 255, 0)  # é»„è‰²
    elif color == 'red':
        color = (255, 0, 0)  # çº¢è‰²
    elif color == 'white':
        color = (255, 255, 255)  # ç™½è‰²
    elif color == 'black':
        color = (0, 0, 0)  # é»‘è‰²
    
    if stroke_color == 'black':
        stroke_color = (0, 0, 0)  # é»‘è‰²æè¾¹
    elif stroke_color == 'white':
        stroke_color = (255, 255, 255)  # ç™½è‰²æè¾¹

    # ç»˜åˆ¶æè¾¹
    stroke_width = 8
    draw.text((x, y), text, font=font, fill=color, stroke_width=stroke_width, stroke_fill=stroke_color)

    return np.array(img)


def create_half_clip_v2(img_path, text, color_rgb, is_top=True, duration=3.0):
    """
    ç”ŸæˆåŠå±è§†é¢‘ç‰‡æ®µ (é€‚é… MoviePy v2)
    """
    h_half = H // 2

    # 1. åŠ è½½å›¾ç‰‡ & å¡«å……åŠå±
    if os.path.exists(img_path):
        img = ImageClip(img_path)
        # å¢åŠ å¯¹æ¯”åº¦ (1.2) å’Œ é¥±å’Œåº¦ (å¦‚æœä¸æ–¹ä¾¿è°ƒé¥±å’Œåº¦ï¼Œè‡³å°‘è°ƒå¯¹æ¯”åº¦)
        img = img.with_effects([vfx.LumContrast(contrast=1.2)])

        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ä»¥å¡«æ»¡åŒºåŸŸ (Cover æ¨¡å¼)
        ratio_img = img.w / img.h
        ratio_target = W / h_half

        if ratio_img < ratio_target:
            # å›¾ç‰‡å¤ªçª„ï¼ŒæŒ‰å®½åº¦ç¼©æ”¾
            img = img.with_effects([vfx.Resize(width=W)])
        else:
            # å›¾ç‰‡å¤ªçŸ®ï¼ŒæŒ‰é«˜åº¦ç¼©æ”¾
            img = img.with_effects([vfx.Resize(height=h_half)])

        # å±…ä¸­è£å‰ª (MoviePy 2.x å†™æ³•)
        img = img.with_effects([vfx.Crop(width=W, height=h_half, x_center=img.w / 2, y_center=img.h / 2)])

    else:
        # å…œåº•çº¯è‰²
        img = ColorClip(size=(W, h_half), color=(50, 50, 50))

    # æ³¨æ„ï¼šMoviePy 2.x çš„ Resize ç‰¹æ•ˆä¸æ”¯æŒ lambda åŠ¨æ€ç¼©æ”¾ (Zoom)
    # ä¸ºäº†ä¿è¯ä»£ç ç¨³å®šæ€§ï¼Œè¿™é‡Œå»æ‰äº†åŠ¨æ€ Zoomï¼Œæ”¹ç”¨æ¸…æ™°çš„é™æ€å±•ç¤º
    # æé€Ÿæµæœ¬èº«åˆ‡æ¢å¾ˆå¿«ï¼Œä¸éœ€è¦ Zoom ä¹Ÿèƒ½æœ‰å†²å‡»åŠ›

    # 2. æŸ“è‰²æ»¤é•œ (Tint Overlay)
    # ä½¿ç”¨åŠé€ ColorClip è¦†ç›–
    tint = ColorClip(size=(W, h_half), color=color_rgb).with_duration(duration).with_opacity(0.2)

    # 3. æ–‡å­— (é€‰é¡¹åç§°)
    # ä½¿ç”¨ PIL ç”Ÿæˆå›¾ç‰‡å†è½¬ ImageClipï¼Œé¿å… v2 TextClip çš„å„ç§æŠ¥é”™
    txt_arr = create_text_img_pil(text, (W, 200))
    # è°ƒæ•´æ–‡å­—ä½ç½®ï¼šä¸ŠåŠéƒ¨åˆ†æ–‡å­—é ä¸‹ï¼Œä¸‹åŠéƒ¨åˆ†æ–‡å­—é ä¸Š
    y_pos = h_half - 250 if is_top else 50
    txt_clip = ImageClip(txt_arr).with_position(('center', y_pos))

    # 4. åˆæˆåŠå±
    return CompositeVideoClip([img, tint, txt_clip], size=(W, h_half))


def create_question_segment_v2(q_data, start_time, duration, is_last_one):
    """ç”Ÿæˆä¸€é“é¢˜çš„å®Œæ•´ç‰‡æ®µ"""

    # 1. åˆ¶ä½œä¸Šä¸‹ä¸¤åŠ
    top_part = create_half_clip_v2(q_data['img_a'], q_data['opt_a'], COLOR_TOP, True, duration)
    bot_part = create_half_clip_v2(q_data['img_b'], q_data['opt_b'], COLOR_BOTTOM, False, duration)

    # 2. æ‹¼åˆ (å‚ç›´å †å )
    # clips_array åœ¨ v2 ä¸­ä¾ç„¶å¯ç”¨
    screen = clips_array([[top_part], [bot_part]])

    # 3. ä¸­é—´åˆ†å‰²çº¿
    vs_bg = ColorClip(size=(W, 10), color=(255, 255, 255)).with_position(('center', 'center'))

    layers = [screen, vs_bg]
    audio_layers = []

    # 4. ç»“æœå±•ç¤ºé€»è¾‘
    if not is_last_one:
        # === æ™®é€šé¢˜ç›®ï¼šæ˜¾ç¤ºç™¾åˆ†æ¯” ===
        reveal_time = duration * 0.6  # æ¯”å¦‚ 3ç§’é¢˜ï¼Œ1.8ç§’å‡ºç»“æœ

        per_a = f"{q_data['per_a']}%"
        per_b = f"{100 - q_data['per_a']}%"

        # ç”Ÿæˆç™¾åˆ†æ¯”å›¾ç‰‡
        img_a = create_text_img_pil(per_a, (400, 150), color='#FFFF00')
        img_b = create_text_img_pil(per_b, (400, 150), color='#FFFF00')

        txt_a = ImageClip(img_a).with_position(('center', 400)).with_start(reveal_time)
        txt_b = ImageClip(img_b).with_position(('center', 1400)).with_start(reveal_time)

        layers.extend([txt_a, txt_b])

        # éŸ³æ•ˆï¼šBoom
        if os.path.exists(SFX_BOOM):
            boom = AudioFileClip(SFX_BOOM).with_start(reveal_time)
            audio_layers.append(boom)

    else:
        # === æœ€åä¸€é¢˜ï¼šäº’åŠ¨é™·é˜± ===
        # æ˜¾ç¤º ??? å’Œ å¼•å¯¼è¯­
        img_bait = create_text_img_pil("???", (400, 150), color='red')
        img_cta = create_text_img_pil("CHOOSE NOW!", (800, 150), color='white')

        bait = ImageClip(img_bait).with_position('center').with_start(0.5)
        cta = ImageClip(img_cta).with_position(('center', 1600)).with_start(0.5)

        layers.extend([bait, cta])

    # 5. ç»„åˆç”»é¢
    # æ³¨æ„ï¼šv2 ä¸­ set_duration, set_start ä¾ç„¶å¯ç”¨ï¼Œä½†æ¨èé“¾å¼è°ƒç”¨
    comp = CompositeVideoClip(layers, size=(W, H)).with_start(start_time).with_duration(duration)

    comp = add_flash_effect(comp)

    # 6. æ·»åŠ å€’è®¡æ—¶éŸ³æ•ˆ (Tick) - [ä¿®å¤ç‰ˆé€»è¾‘]
    if os.path.exists(SFX_TICK):
        try:
            tick = AudioFileClip(SFX_TICK).with_volume_scaled(0.8)

            # === æ ¸å¿ƒä¿®å¤ï¼šè‡ªåŠ¨å¾ªç¯çŸ­éŸ³é¢‘ ===
            # å¦‚æœéŸ³é¢‘æ¯”éœ€è¦çš„æ—¶é•¿çŸ­ï¼Œå°±å¤åˆ¶æ‹¼æ¥ï¼Œç›´åˆ°å¤Ÿé•¿ä¸ºæ­¢
            if tick.duration < duration:
                # è®¡ç®—éœ€è¦å¾ªç¯å¤šå°‘æ¬¡ (ä¾‹å¦‚ 3.0 / 1.46 â‰ˆ 2.05 -> å¾ªç¯3æ¬¡)
                n_loops = int(duration / tick.duration) + 1
                # æ‹¼æ¥éŸ³é¢‘
                tick = concatenate_audioclips([tick] * n_loops)

            # ç°åœ¨éŸ³é¢‘è¶³å¤Ÿé•¿äº†ï¼Œå®‰å…¨æˆªå–
            tick = tick.subclipped(0, duration)

            # å°† tick åŠ å…¥éŸ³é¢‘åˆ—è¡¨
            audio_layers.insert(0, tick)
        except Exception as e:
            print(f"âš ï¸ éŸ³é¢‘å¤„ç†è­¦å‘Š: {e}")

    # 7. åˆæˆéŸ³é¢‘
    if audio_layers:
        comp_audio = CompositeAudioClip(audio_layers)
        comp = comp.with_audio(comp_audio)



    return comp


def get_day_data(day_index):
    """
    è·å–ç¬¬ day_index (1-14) å¤©çš„é¢˜ç›®æ•°æ®
    è‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡è·¯å¾„
    """
    base_path = f"assets/speedrun/day{day_index}"

    # === 14å¤©é¢˜åº“æ€»è¡¨ ===
    all_questions = {
        1: [  # Day 1: Classic (ç»å…¸)
            ("RICH", "HANDSOME", 76),
            ("FLY", "INVISIBLE", 64),
            ("SAVE MOM", "SAVE DAD", 0)  # 0 è¡¨ç¤ºä¸æ˜¾ç¤ºç»“æœ(é™·é˜±)
        ],
        2: [  # Day 2: Marvel Powers (æ¼«å¨èƒ½åŠ›)
            ("IRON SUIT", "CAP SHIELD", 68),
            ("THOR HAMMER", "HULK POWER", 55),
            ("KILL THANOS", "KILL LOKI", 0)
        ],
        3: [  # Day 3: Gaming (æ¸¸æˆ)
            ("FREE WIFI", "FREE FOOD", 82),
            ("PLAYSTATION", "XBOX", 60),
            ("UNLIMITED GAMES", "UNLIMITED MONEY", 0)
        ],
        4: [  # Day 4: Horror (ææ€–)
            ("ZOMBIES", "GHOSTS", 45),
            ("VAMPIRE", "WEREWOLF", 52),
            ("TRAPPED IN OCEAN", "TRAPPED IN SPACE", 0)
        ],
        5: [  # Day 5: Food (é£Ÿç‰©)
            ("PIZZA", "BURGER", 51),
            ("COKE", "PEPSI", 70),
            ("ONLY SWEET", "ONLY SALTY", 0)
        ],
        6: [  # Day 6: School (å­¦æ ¡)
            ("NO HOMEWORK", "NO EXAMS", 55),
            ("SMARTEST", "POPULAR", 40),
            ("10Y SCHOOL", "10Y PRISON", 0)
        ],
        7: [  # Day 7: Love/Money (äººæ€§)
            ("TRUE LOVE", "10 MILLION", 35),
            ("CHEAT", "BE CHEATED", 10),
            ("DATE EX", "DATE BOSS", 0)
        ],
        8: [  # Day 8: Spider-Man Special (èœ˜è››ä¾ ä¸“åœº)
            ("MJ", "GWEN STACY", 48),
            ("TOBEY", "TOM HOLLAND", 58),
            ("SAVE SPIDEY", "SAVE IRON MAN", 0)
        ],
        9: [  # Day 9: Marvel vs DC (è·¨ç•Œ)
            ("IRON MAN", "BATMAN", 52),
            ("THOR", "SUPERMAN", 45),
            ("JOKER", "THANOS", 0)
        ],
        10: [  # Day 10: Superpowers (è¶…èƒ½åŠ›)
            ("READ MINDS", "SEE FUTURE", 65),
            ("TELEPORT", "TIME TRAVEL", 72),
            ("STOP TIME", "REWIND TIME", 0)
        ],
        11: [  # Day 11: Harry Potter (å“ˆåˆ©æ³¢ç‰¹)
            ("GRYFFINDOR", "SLYTHERIN", 60),
            ("HARRY", "DRACO", 55),
            ("SAVE DOBBY", "SAVE DUMBLEDORE", 0)
        ],
        12: [  # Day 12: Survival (ç”Ÿå­˜)
            ("ZOMBIE APOCALYPSE", "ALIEN INVASION", 42),
            ("FREEZE TO DEATH", "BURN TO DEATH", 50),
            ("HUNT", "BE HUNTED", 0)
        ],
        13: [  # Day 13: Life Inconvenience (ç”Ÿæ´»)
            ("NO PHONE", "NO TV", 20),
            ("NO MUSIC", "NO MOVIES", 30),
            ("TALK TO ANIMALS", "SPEAK ALL LANGS", 0)
        ],
        14: [  # Day 14: The End (ç»ˆæ)
            ("RED PILL", "BLUE PILL", 50),
            ("RESTART LIFE", "SKIP TO END", 80),
            ("WORLD PEACE", "1 BILLION $", 0)
        ]
    }

    questions = all_questions.get(day_index, [])
    formatted_data = []

    for i, q in enumerate(questions):
        q_idx = i + 1
        formatted_data.append({
            "opt_a": q[0],
            "img_a": os.path.join(base_path, f"q{q_idx}_a.jpg"),
            "opt_b": q[1],
            "img_b": os.path.join(base_path, f"q{q_idx}_b.jpg"),
            "per_a": q[2]
        })

    return formatted_data

def add_flash_effect(clip):
    """ç»™ç‰‡æ®µå¼€å¤´åŠ ä¸€ä¸ªæçŸ­çš„ç™½é—ª"""
    # åˆ›å»ºä¸€ä¸ª 0.15ç§’ çš„ç™½è‰²ç‰‡æ®µ - ä½¿ç”¨ RGB å€¼æ›¿ä»£å­—ç¬¦ä¸²
    flash = ColorClip(size=(W, H), color=(255, 255, 255)).with_duration(0.15).with_opacity(0.6)
    # å åŠ åœ¨åŸç‰‡æ®µå¼€å¤´
    return CompositeVideoClip([clip, flash.with_start(0)])

def main():
    # === æ‰¹é‡ç”Ÿæˆè®¾ç½® ===
    # ä½ å¯ä»¥æ”¹ä¸º range(1, 15) ä¸€æ¬¡ç”Ÿæˆæ‰€æœ‰ï¼Œæˆ–è€…æŒ‡å®šæŸä¸€å¤©
    # DAYS_TO_GENERATE = [1]
    DAYS_TO_GENERATE = range(2, 15)

    print(f"ğŸš€ å‡†å¤‡ç”Ÿæˆ {len(DAYS_TO_GENERATE)} ä¸ªæé€Ÿæµè§†é¢‘...")

    for day in DAYS_TO_GENERATE:
        day_data = get_day_data(day)

        # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨ï¼Œé¿å…æŠ¥é”™
        if not os.path.exists(day_data[0]['img_a']):
            print(f"âŒ Day {day} ç´ æç¼ºå¤±ï¼Œè¯·æ£€æŸ¥è·¯å¾„: {day_data[0]['img_a']}")
            continue

        print(f"ğŸ¬ æ­£åœ¨æ¸²æŸ“ Day {day} ...")

        # æé€Ÿæ—¶é—´è½´ (10ç§’)
        clip1 = create_question_segment_v2(day_data[0], 0, 3.0, False)
        clip2 = create_question_segment_v2(day_data[1], 3.0, 3.0, False)
        clip3 = create_question_segment_v2(day_data[2], 6.0, 4.0, True)

        final = CompositeVideoClip([clip1, clip2, clip3], size=(W, H)).with_duration(10.0)

        output_filename = f"target/Speedrun_Day{day}.mp4"
        final.write_videofile(
            output_filename,
            fps=30,
            codec='libx264',
            audio_codec='aac',
            threads=4,
            preset='ultrafast'
        )
        print(f"âœ… Day {day} å®Œæˆï¼")


if __name__ == "__main__":
    main()