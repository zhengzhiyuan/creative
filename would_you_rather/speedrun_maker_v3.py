import os
import random
import asyncio
import edge_tts
import numpy as np  # æ–°å¢æ­¤è¡Œ
from PIL import Image, ImageDraw, ImageFont

# === MoviePy 2.x å¯¼å…¥ ===
from moviepy import (
    VideoFileClip, ImageClip, ColorClip, TextClip,
    CompositeVideoClip, clips_array, AudioFileClip,
    CompositeAudioClip, concatenate_audioclips,
    concatenate_videoclips  # <--- æ ¸å¿ƒä¿®å¤ï¼šå¿…é¡»ç”¨è¿™ä¸ª
)
import moviepy.video.fx as vfx

# ================= é…ç½®åŒºåŸŸ =================
W, H = 1080, 1920
COLOR_TOP = (200, 0, 0)
COLOR_BOTTOM = (0, 0, 200)
FONT_PATH = "Impact.ttf"

SFX_TICK = "assets/sfx/tick.mp3"
SFX_BOOM = "assets/sfx/boom.mp3"

# === TTS é…ç½® (å…³é”®è¿­ä»£) ===
# æ¨èå£°éŸ³:
# "en-US-ChristopherNeural" (ç”·å£°ï¼Œç±»ä¼¼ç”µå½±è§£è¯´)
# "en-US-AnaNeural" (å¥³å£°ï¼Œæ¸…æ™°)
TTS_VOICE = "en-US-ChristopherNeural"
TTS_RATE = "+35%"  # è¯­é€ŸåŠ é€Ÿ 35%ï¼Œåˆ¶é€ ç´§è¿«æ„Ÿ


# ================= å·¥å…·å‡½æ•° =================

# ... (create_text_img_pil å’Œ create_half_clip_v2 ä¿æŒä¸å˜ï¼Œç›´æ¥å¤ç”¨ v2 çš„ä»£ç ) ...
# ä¸ºäº†èŠ‚çœç¯‡å¹…ï¼Œè¿™é‡Œçœç•¥è¿™ä¸¤ä¸ªè§†è§‰å‡½æ•°çš„ä»£ç ï¼Œè¯·ç¡®ä¿å®ƒä»¬åœ¨ä½ çš„æ–‡ä»¶ä¸­
def create_text_img_pil(text, size, color='white', stroke_color='black'):
    img = Image.new("RGBA", size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    try:
        font = ImageFont.truetype(FONT_PATH, 100)
    except:
        font = ImageFont.load_default()
    bbox = draw.textbbox((0, 0), text, font=font)
    text_w, text_h = bbox[2] - bbox[0], bbox[3] - bbox[1]
    x, y = (size[0] - text_w) / 2, (size[1] - text_h) / 2
    draw.text((x, y), text, font=font, fill=color, stroke_width=8, stroke_fill=stroke_color)
    return np.array(img)


def create_half_clip_v2(img_path, text, color_rgb, is_top=True):
    h_half = H // 2
    if os.path.exists(img_path):
        img = ImageClip(img_path)

        ratio_img = img.w / img.h
        ratio_target = W / h_half
        if ratio_img < ratio_target:
            img = img.with_effects([vfx.Resize(width=W)])
        else:
            img = img.with_effects([vfx.Resize(height=h_half)])
        img = img.with_effects([vfx.Crop(width=W, height=h_half, x_center=img.w / 2, y_center=img.h / 2)])
        # è‰²å½©å¢å¼º (V1.5 è¿­ä»£)
        img = img.with_effects([vfx.LumContrast(contrast=1.2)]) # éœ€ç¡®è®¤MoviePyç‰ˆæœ¬æ˜¯å¦æ”¯æŒæ­¤å†™æ³•
    else:
        img = ColorClip(size=(W, h_half), color=(50, 50, 50))

    tint = ColorClip(size=(W, h_half), color=color_rgb).with_opacity(0.2)
    txt_arr = create_text_img_pil(text, (W, 200))
    y_pos = h_half - 250 if is_top else 50
    txt_clip = ImageClip(txt_arr).with_position(('center', y_pos))
    return CompositeVideoClip([img, tint, txt_clip], size=(W, h_half))


# ================= æ ¸å¿ƒå¼‚æ­¥é€»è¾‘ =================

async def generate_tts_audio(text, filename):
    """ä½¿ç”¨ Edge-TTS ç”ŸæˆåŠ é€Ÿè¯­éŸ³"""
    communicate = edge_tts.Communicate(text, TTS_VOICE, rate=TTS_RATE)
    await communicate.save(filename)
    return filename


async def create_question_segment_v3(q_data, start_time, duration, is_last_one, temp_id):
    """
    ç”Ÿæˆå•é¢˜ç‰‡æ®µ (åŒ…å« TTS)
    temp_id: ç”¨äºåŒºåˆ†ä¸´æ—¶æ–‡ä»¶
    """
    # 1. ç”»é¢ç”Ÿæˆ (åŒ v2)
    top_part = create_half_clip_v2(q_data['img_a'], q_data['opt_a'], COLOR_TOP, True)
    bot_part = create_half_clip_v2(q_data['img_b'], q_data['opt_b'], COLOR_BOTTOM, False)
    screen = clips_array([[top_part], [bot_part]])

    # ç™½é—ªç‰¹æ•ˆ (Visual Flash)
    flash = ColorClip(size=(W, H), color=(255, 255, 255)).with_duration(0.15).with_opacity(0.5).with_start(0)

    vs_bg = ColorClip(size=(1920, 10), color=(255, 255, 255)).with_position(('center', 'center'))
    layers = [screen, vs_bg, flash]
    audio_layers = []

    # 2. TTS ç”Ÿæˆ (æ–°å¢!)
    # æ–‡æ¡ˆé€»è¾‘: "Option A or Option B?"
    tts_text = f"{q_data['opt_a']} or {q_data['opt_b']}?"
    if is_last_one:
        tts_text += " Choose Now!"

    tts_filename = f"temp_tts_{temp_id}.mp3"
    await generate_tts_audio(tts_text, tts_filename)

    if os.path.exists(tts_filename):
        tts_clip = AudioFileClip(tts_filename).with_start(0)  # ä¸€å¼€å§‹å°±è¯»
        # ç¡®ä¿ TTS ä¸ä¼šè¶…è¿‡è§†é¢‘ç‰‡æ®µæ—¶é•¿ (è™½ç„¶åŠ é€Ÿåä¸€èˆ¬å¾ˆçŸ­)
        if tts_clip.duration > duration:
            tts_clip = tts_clip.subclipped(0, duration)
        audio_layers.append(tts_clip)

    # 3. ç»“æœå±•ç¤º (åŒ v2)
    if not is_last_one:
        reveal_time = duration * 0.6
        per_a = f"{q_data['per_a']}%"
        per_b = f"{100 - q_data['per_a']}%"

        img_a = create_text_img_pil(per_a, (400, 150), color='#FFFF00')
        img_b = create_text_img_pil(per_b, (400, 150), color='#FFFF00')

        txt_a = ImageClip(img_a).with_position(('center', 400)).with_start(reveal_time)
        txt_b = ImageClip(img_b).with_position(('center', 1400)).with_start(reveal_time)
        layers.extend([txt_a, txt_b])

        if os.path.exists(SFX_BOOM):
            boom = AudioFileClip(SFX_BOOM).with_start(reveal_time).with_volume_scaled(0.8)
            audio_layers.append(boom)
    else:
        # æœ€åä¸€é¢˜é™·é˜±
        # å»ºè®®ä½¿ç”¨ä¹‹å‰è¯´çš„ "assets/ui/question_marks.png" æ›¿ä»£ä»£ç ç”»å›¾
        img_bait = create_text_img_pil("???", (400, 150), color='red')
        img_cta = create_text_img_pil("CHOOSE NOW!", (800, 150), color='white')
        bait = ImageClip(img_bait).with_position('center').with_start(0.5)
        cta = ImageClip(img_cta).with_position(('center', 1600)).with_start(0.5)
        layers.extend([bait, cta])

    # 4. åˆæˆç‰‡æ®µ
    comp = CompositeVideoClip(layers, size=(W, H)).with_start(start_time).with_duration(duration)

    # 5. éŸ³æ•ˆæ··åˆ (TTS + Tick)
    if os.path.exists(SFX_TICK):
        tick = AudioFileClip(SFX_TICK).with_volume_scaled(0.6)  # ç¨å¾®è°ƒå°Tickï¼Œå‡¸æ˜¾äººå£°
        if tick.duration < duration:
            n_loops = int(duration / tick.duration) + 1
            tick = concatenate_audioclips([tick] * n_loops)
        tick = tick.subclipped(0, duration)
        audio_layers.insert(0, tick)

    if audio_layers:
        comp = comp.with_audio(CompositeAudioClip(audio_layers))

    return comp, tts_filename

def get_day_data(day_index):
    """
    è·å–ç¬¬ day_index (1-14) å¤©çš„é¢˜ç›®æ•°æ®
    è‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡è·¯å¾„
    """
    base_path = f"assets/speedrun/day{day_index}"

    # === 14å¤©é¢˜åº“æ€»è¡¨ ===
    all_questions = {
        1: [  # Day 1: Classic (ç»å…¸)
            ("RICH", "HANDSOME", 76),
            ("FLY", "INVISIBLE", 64),
            ("SAVE MOM", "SAVE DAD", 0)  # 0 è¡¨ç¤ºä¸æ˜¾ç¤ºç»“æœ(é™·é˜±)
        ],
        2: [  # Day 2: Marvel Powers (æ¼«å¨èƒ½åŠ›)
            ("IRON SUIT", "CAP SHIELD", 68),
            ("THOR HAMMER", "HULK POWER", 55),
            ("KILL THANOS", "KILL LOKI", 0)
        ],
        3: [  # Day 3: Gaming (æ¸¸æˆ)
            ("FREE WIFI", "FREE FOOD", 82),
            ("PLAYSTATION", "XBOX", 60),
            ("UNLIMITED GAMES", "UNLIMITED MONEY", 0)
        ],
        4: [  # Day 4: Horror (ææ€–)
            ("ZOMBIES", "GHOSTS", 45),
            ("VAMPIRE", "WEREWOLF", 52),
            ("TRAPPED IN OCEAN", "TRAPPED IN SPACE", 0)
        ],
        5: [  # Day 5: Food (é£Ÿç‰©)
            ("PIZZA", "BURGER", 51),
            ("COKE", "PEPSI", 70),
            ("ONLY SWEET", "ONLY SALTY", 0)
        ],
        6: [  # Day 6: School (å­¦æ ¡)
            ("NO HOMEWORK", "NO EXAMS", 55),
            ("SMARTEST", "POPULAR", 40),
            ("10Y SCHOOL", "10Y PRISON", 0)
        ],
        7: [  # Day 7: Love/Money (äººæ€§)
            ("TRUE LOVE", "10 MILLION", 35),
            ("CHEAT", "BE CHEATED", 10),
            ("DATE EX", "DATE BOSS", 0)
        ],
        8: [  # Day 8: Spider-Man Special (èœ˜è››ä¾ ä¸“åœº)
            ("MJ", "GWEN STACY", 48),
            ("TOBEY", "TOM HOLLAND", 58),
            ("SAVE SPIDEY", "SAVE IRON MAN", 0)
        ],
        9: [  # Day 9: Marvel vs DC (è·¨ç•Œ)
            ("IRON MAN", "BATMAN", 52),
            ("THOR", "SUPERMAN", 45),
            ("JOKER", "THANOS", 0)
        ],
        10: [  # Day 10: Superpowers (è¶…èƒ½åŠ›)
            ("READ MINDS", "SEE FUTURE", 65),
            ("TELEPORT", "TIME TRAVEL", 72),
            ("STOP TIME", "REWIND TIME", 0)
        ],
        11: [  # Day 11: Harry Potter (å“ˆåˆ©æ³¢ç‰¹)
            ("GRYFFINDOR", "SLYTHERIN", 60),
            ("HARRY", "DRACO", 55),
            ("SAVE DOBBY", "SAVE DUMBLEDORE", 0)
        ],
        12: [  # Day 12: Survival (ç”Ÿå­˜)
            ("ZOMBIE APOCALYPSE", "ALIEN INVASION", 42),
            ("FREEZE TO DEATH", "BURN TO DEATH", 50),
            ("HUNT", "BE HUNTED", 0)
        ],
        13: [  # Day 13: Life Inconvenience (ç”Ÿæ´»)
            ("NO PHONE", "NO TV", 20),
            ("NO MUSIC", "NO MOVIES", 30),
            ("TALK TO ANIMALS", "SPEAK ALL LANGS", 0)
        ],
        14: [  # Day 14: The End (ç»ˆæ)
            ("RED PILL", "BLUE PILL", 50),
            ("RESTART LIFE", "SKIP TO END", 80),
            ("WORLD PEACE", "1 BILLION $", 0)
        ]
    }

    questions = all_questions.get(day_index, [])
    formatted_data = []

    for i, q in enumerate(questions):
        q_idx = i + 1
        formatted_data.append({
            "opt_a": q[0],
            "img_a": os.path.join(base_path, f"q{q_idx}_a.jpg"),
            "opt_b": q[1],
            "img_b": os.path.join(base_path, f"q{q_idx}_b.jpg"),
            "per_a": q[2]
        })

    return formatted_data


async def main_async(day_data, day):
    # ç¤ºä¾‹æ•°æ® (è¯·æ›¿æ¢ä¸ºä½ çš„ get_day_data é€»è¾‘)
    print(f"ğŸš€ æ­£åœ¨ç”Ÿæˆå¸¦Day{day} TTS çš„æé€Ÿæµè§†é¢‘...")

    temp_files = []

    # å¹¶å‘ç”Ÿæˆä¸‰ä¸ªç‰‡æ®µ
    # Q1: 3s | Q2: 3s | Q3: 4s
    task1 = create_question_segment_v3(day_data[0], 0, 3.0, False, "q1")
    task2 = create_question_segment_v3(day_data[1], 3.0, 3.0, False, "q2")
    task3 = create_question_segment_v3(day_data[2], 6.0, 4.0, True, "q3")

    results = await asyncio.gather(task1, task2, task3)

    clips = [res[0] for res in results]
    temp_files = [res[1] for res in results]

    final = concatenate_videoclips(clips, method="compose")

    output_filename = f"target/Day{day}_TTS_Speedrun_v3.mp4"
    final.write_videofile(
        output_filename,
        fps=30,
        codec='libx264',
        audio_codec='aac',
        threads=4,
        preset='ultrafast'
    )

    print("ğŸ§¹ æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶...")
    for f in temp_files:
        if os.path.exists(f):
            os.remove(f)

    print(f"âœ… å®Œæˆï¼æ–‡ä»¶: {output_filename}")


def main():
    DAYS_TO_GENERATE = range(1, 15)
    # DAYS_TO_GENERATE = [1]

    print(f"ğŸš€ å‡†å¤‡ç”Ÿæˆ {len(DAYS_TO_GENERATE)} ä¸ªæé€Ÿæµè§†é¢‘...")

    for day in DAYS_TO_GENERATE:
        day_data = get_day_data(day)
        asyncio.run(main_async(day_data,day))


if __name__ == "__main__":
    main()