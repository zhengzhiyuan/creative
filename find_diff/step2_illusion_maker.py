import os
import random
import asyncio
import numpy as np
from PIL import Image, ImageDraw, ImageFont

# === MoviePy 2.2.1 ä¸“ç”¨å¯¼å…¥ ===
from moviepy import (
    VideoFileClip, ImageClip, ColorClip, TextClip,
    CompositeVideoClip, clips_array, AudioFileClip,
    CompositeAudioClip, concatenate_audioclips,
    concatenate_videoclips
)
import moviepy.video.fx as vfx
import edge_tts

# ================= é…ç½®åŒºåŸŸ =================
W, H = 1080, 1920
FONT_PATH = "Impact.ttf"
# Macç”¨æˆ·ä¸“ç”¨ Emoji è·¯å¾„
EMOJI_FONT_PATH = "/System/Library/Fonts/Apple Color Emoji.ttc"

SFX_TICK = "assets/sfx/tick.mp3"
SFX_BOOM = "assets/sfx/boom.mp3"
SFX_MAGIC = "assets/sfx/boom.mp3"

TTS_VOICE = "en-US-ChristopherNeural"
TTS_RATE = "+25%"

# ================= 14å¤© Emoji æ•°æ®é…ç½® =================
DAY_CONFIG = {
    "day1": {"main": "ğŸ”´", "odd": "ğŸ›‘", "name": "Iron Man"},
    "day2": {"main": "ğŸ¤¢", "odd": "ğŸ¤®", "name": "Hulk"},
    "day3": {"main": "ğŸ•·ï¸", "odd": "ğŸœ", "name": "Spidey"},
    "day4": {"main": "âš¡", "odd": "âœ¨", "name": "Pikachu"},
    "day5": {"main": "ğŸ¤¡", "odd": "ğŸ‘º", "name": "Joker"},
    "day6": {"main": "ğŸ›¡ï¸", "odd": "âš™ï¸", "name": "Cap"},
    "day7": {"main": "ğŸ–¤", "odd": "ğŸ’£", "name": "Venom"},
    "day8": {"main": "ğŸ„", "odd": "ğŸŒ¹", "name": "Mario"},
    "day9": {"main": "ğŸŸ¨", "odd": "ğŸŸ§", "name": "SpongeBob"},
    "day10": {"main": "ğŸŒ", "odd": "ğŸŒ™", "name": "Minion"},
    "day11": {"main": "ğŸ¦‡", "odd": "ğŸ¦…", "name": "Batman"},
    "day12": {"main": "âš”ï¸", "odd": "ğŸ”ª", "name": "Deadpool"},
    "day13": {"main": "â„ï¸", "odd": "ğŸ§Š", "name": "Elsa"},
    "day14": {"main": "ğŸš€", "odd": "ğŸ›¸", "name": "Buzz"}
}


# ================= è¾…åŠ©å‡½æ•° =================

def create_text_img_pil(text, size, color='white', font_size=100, stroke_color='black'):
    # ç”Ÿæˆé€æ˜èƒŒæ™¯
    img = Image.new("RGBA", size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)

    # é¢œè‰²è½¬æ¢é€»è¾‘
    if color == 'white':
        color = (255, 255, 255)
    elif color == 'red':
        color = (255, 0, 0)
    elif color == 'yellow':
        color = (255, 255, 0)
    elif color == 'black':
        color = (0, 0, 0)

    if stroke_color == 'white':
        stroke_color = (255, 255, 255)
    elif stroke_color == 'black':
        stroke_color = (0, 0, 0)

    # === ä¿®å¤ç‚¹ï¼šå¼ºåˆ¶è½¬æ¢ä¸ºæ•´æ•°ï¼Œä¸”è‡³å°‘ä¸º 1 ===
    valid_font_size = max(10, int(font_size))

    try:
        font = ImageFont.truetype(FONT_PATH, valid_font_size)
    except Exception as e:
        print(f"âš ï¸ è‡ªå®šä¹‰å­—ä½“åŠ è½½å¤±è´¥ ({e})ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
        font = ImageFont.load_default()

    bbox = draw.textbbox((0, 0), text, font=font)
    text_w, text_h = bbox[2] - bbox[0], bbox[3] - bbox[1]
    x, y = (size[0] - text_w) / 2, (size[1] - text_h) / 2

    draw.text((x, y), text, font=font, fill=color, stroke_width=6, stroke_fill=stroke_color)
    return np.array(img)


def create_emoji_grid(main, odd, rows=7, cols=6):
    """
    ç”Ÿæˆ Emoji çŸ©é˜µ (ä¿®å¤ invalid pixel size é—®é¢˜)
    """
    # èƒŒæ™¯é€æ˜
    img = Image.new("RGBA", (W, 1000), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)

    target_r = random.randint(0, rows - 1)
    target_c = random.randint(0, cols - 1)

    cell_w = W // cols
    cell_h = 1000 // rows

    # === ä¿®å¤ç‚¹ï¼šå¼ºåˆ¶è½¬ä¸ºæ•´æ•° ===
    raw_size = min(cell_w, cell_h) * 0.75
    font_size = max(10, int(raw_size))  # ç¡®ä¿æ˜¯æ•´æ•°ä¸”ä¸å°äº10

    try:
        # Mac éœ€è¦ index=0
        font = ImageFont.truetype(EMOJI_FONT_PATH, font_size, index=0)
    except Exception as e:
        print(f"âš ï¸ Emoji å­—ä½“åŠ è½½å¤±è´¥: {e} (Size: {font_size})")
        # å°è¯•å¤‡ç”¨æ–¹æ¡ˆ (ä¸å¸¦ index)
        try:
            font = ImageFont.truetype(EMOJI_FONT_PATH, font_size)
        except:
            print("âš ï¸ å½»åº•å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“ (å¯èƒ½ä¸æ˜¾ç¤ºEmoji)")
            font = ImageFont.load_default()

    for r in range(rows):
        for c in range(cols):
            char = odd if (r == target_r and c == target_c) else main

            # è®¡ç®—å±…ä¸­åæ ‡
            x = c * cell_w + (cell_w - font_size) / 2
            y = r * cell_h + (cell_h - font_size) / 2

            # å¿…é¡» int() åæ ‡ï¼Œé˜²æ­¢éƒ¨åˆ†ç³»ç»ŸæŠ¥é”™
            draw.text((int(x), int(y)), char, font=font, embedded_color=True, fill='black')

    return np.array(img)


# ================= æ ¸å¿ƒç”Ÿæˆé€»è¾‘ =================

async def generate_tts(text, filename):
    communicate = edge_tts.Communicate(text, TTS_VOICE, rate=TTS_RATE)
    await communicate.save(filename)
    return filename


async def create_illusion_video(day_key):
    print(f"ğŸ¬ æ­£åœ¨åˆ¶ä½œ {day_key} ...")

    assets_dir = f"assets/illusion/{day_key}"
    img_path = os.path.join(assets_dir, "illusion.jpg")

    if not os.path.exists(img_path):
        print(f"âŒ å›¾ç‰‡ç¼ºå¤±: {img_path}")
        return

    # === Part 1: è§†è§‰é”™è§‰ Hook (0s - 8s) ===

    base_img = ImageClip(img_path).with_effects([
        vfx.Resize(height=1920),
        vfx.Crop(width=W, height=H, x_center=W / 2, y_center=H / 2)
    ])

    clip_inverted = base_img.with_effects([vfx.InvertColors()]).with_duration(5.0)
    clip_bw = base_img.with_effects([vfx.BlackAndWhite()]).with_duration(3.0)

    # çº¢ç‚¹ (è§†è§‰é”šç‚¹)
    red_dot = (ColorClip(size=(20, 20), color=(255, 0, 0))
               .with_position('center').with_duration(8.0))

    # æŒ‡ä»¤æ–‡å­—
    txt_instr = (ImageClip(create_text_img_pil("STARE AT THE DOT", (W, 200), color=(255, 255, 0)))
                 .with_position(('center', 300)).with_duration(5.0))

    txt_blink = (ImageClip(create_text_img_pil("DO NOT BLINK!", (W, 200), color=(255, 0, 0)))
                 .with_position(('center', 1500)).with_duration(5.0))

    visual_track = concatenate_videoclips([clip_inverted, clip_bw])
    part1_hook = CompositeVideoClip([visual_track, red_dot, txt_instr, txt_blink]).with_duration(8.0)

    # === Part 2: Emoji æ¸¸æˆ (8s - 15s) ===

    emoji_data = DAY_CONFIG.get(day_key, {"main": "â“", "odd": "â”", "name": "Unknown"})
    emoji_img = create_emoji_grid(emoji_data['main'], emoji_data['odd'])

    # æ¸¸æˆèƒŒæ™¯ (äº®ç™½è‰²)
    bg_white = ColorClip(size=(W, H), color=(255, 255, 255)).with_duration(7.0)

    # Emoji çŸ©é˜µ (é€æ˜èƒŒæ™¯å åŠ åœ¨ç™½åº•ä¸Š)
    emoji_clip = ImageClip(emoji_img).with_position('center').with_duration(7.0)
    # ç®€å•çš„å‘¼å¸åŠ¨ç”»
    emoji_clip = emoji_clip.with_effects([vfx.Resize(lambda t: 1 + 0.02 * t)])

    # æ–‡å­—
    txt_game = (
        ImageClip(create_text_img_pil("FIND THE ODD ONE", (W, 200), color=(0, 0, 0), stroke_color=(255, 255, 255)))
        .with_position(('center', 150)).with_duration(7.0))

    txt_cta = (ImageClip(
        create_text_img_pil("SUBSCRIBE IF YOU FOUND IT", (W, 200), color=(255, 0, 0), stroke_color=(255, 255, 255)))
               .with_position(('center', 1600)).with_duration(7.0))

    part2_game = CompositeVideoClip([bg_white, emoji_clip, txt_game, txt_cta]).with_duration(7.0)

    # === Part 3: éŸ³é¢‘å¤„ç† ===

    audio_tracks = []

    # TTS 1: Hook
    tts_1_file = f"temp_tts_hook_{day_key}.mp3"
    await generate_tts("Stare at the red dot. Focus. Do not blink.", tts_1_file)
    if os.path.exists(tts_1_file):
        audio_tracks.append(AudioFileClip(tts_1_file).with_start(0))

    # TTS 2: Reveal
    tts_2_file = f"temp_tts_reveal_{day_key}.mp3"
    await generate_tts("Now look! Did you see the color?", tts_2_file)
    if os.path.exists(tts_2_file):
        audio_tracks.append(AudioFileClip(tts_2_file).with_start(5.0))

    # TTS 3: Game
    tts_3_file = f"temp_tts_game_{day_key}.mp3"
    await generate_tts(f"Now level 2. Find the odd {emoji_data['name']} emoji!", tts_3_file)
    if os.path.exists(tts_3_file):
        audio_tracks.append(AudioFileClip(tts_3_file).with_start(8.0))

    # SFX: é­”æ³•éŸ³æ•ˆ
    if os.path.exists(SFX_MAGIC):
        audio_tracks.append(AudioFileClip(SFX_MAGIC).with_start(5.0))

    # SFX: Tick (å€’è®¡æ—¶) - å·²åŠ å…¥é˜²æ­¢å´©æºƒçš„å¾ªç¯é€»è¾‘
    if os.path.exists(SFX_TICK):
        try:
            tick_source = AudioFileClip(SFX_TICK)
            target_dur = 7.0
            if tick_source.duration < target_dur:
                n_loops = int(target_dur / tick_source.duration) + 1
                tick_looped = concatenate_audioclips([tick_source] * n_loops)
            else:
                tick_looped = tick_source

            tick = tick_looped.subclipped(0, target_dur) \
                .with_start(8.0) \
                .with_volume_scaled(0.5)
            audio_tracks.append(tick)
        except Exception as e:
            print(f"âš ï¸ Tick éŸ³æ•ˆå¤„ç†é”™è¯¯: {e}")

    # === æœ€ç»ˆåˆæˆ ===
    final_video = concatenate_videoclips([part1_hook, part2_game])
    if audio_tracks:
        final_video = final_video.with_audio(CompositeAudioClip(audio_tracks))

    out_file = f"Illusion_Day_{day_key}.mp4"
    final_video.write_videofile(out_file, fps=30, codec='libx264', audio_codec='aac', threads=4, preset='ultrafast')

    # æ¸…ç†
    for f in [tts_1_file, tts_2_file, tts_3_file]:
        if os.path.exists(f): os.remove(f)

    print(f"âœ… å®Œæˆ: {out_file}")


async def main():
    # ä¸ºäº†æµ‹è¯•ï¼Œè¿™é‡Œåªç”Ÿæˆ day1
    # å¦‚æœè¦ç”Ÿæˆå…¨éƒ¨ï¼Œæ”¹ä¸º: for i in range(1, 15): await create_illusion_video(f"day{i}")
    await create_illusion_video("day1")


if __name__ == "__main__":
    asyncio.run(main())